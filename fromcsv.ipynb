{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO7GnW47XkSxl94UOMs6d+6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alkang53/CNN-BASED-TEXT-CLASSIFICATION/blob/main/fromcsv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9J-KDLWZtwz",
        "outputId": "66b8981b-b961-4eff-fe85-7cbe72665c80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "from scipy.io import arff\n",
        "import pandas as pd\n",
        "import csv\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
        "import numpy as np\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import time\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn import svm\n",
        "\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv1D, MaxPooling2D, Dropout, Input, Embedding\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TTC4900 - kelimelerin orj halini içeren csv\n",
        "csv_file = '/content/drive/My Drive/7allV03.csv'\n",
        "data = pd.read_csv(csv_file)\n",
        "\n",
        "corpus = data['text']\n",
        "categoryNum = 7"
      ],
      "metadata": {
        "id": "gpqrq6w4aJrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TTC4900 - kelimelerin köklerini içeren csv\n",
        "csv_file = '/content/drive/My Drive/7allV03_lem.csv'\n",
        "data = pd.read_csv(csv_file)\n",
        "\n",
        "corpus = data['text']\n",
        "categoryNum = 7"
      ],
      "metadata": {
        "id": "40eVgl2rumz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#müşteri yorumları - kelimelerin orj halini içeren csv\n",
        "csv_file = '/content/drive/My Drive/e-ticaret_urun_yorumlari_as.csv'\n",
        "data = pd.read_csv(csv_file, sep=';')\n",
        "\n",
        "corpus = data['text']\n",
        "categoryNum = 2"
      ],
      "metadata": {
        "id": "eSSRaUy0r0Lo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#müşteri yorumları - kelimelerin köklerini içeren csv\n",
        "csv_file = '/content/drive/My Drive/e-ticaret_urun_yorumlari_lem.csv'\n",
        "data = pd.read_csv(csv_file, sep=';')\n",
        "\n",
        "corpus = data['text']\n",
        "categoryNum = 2"
      ],
      "metadata": {
        "id": "1PRe6j6wr0o2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#+ Stopwords\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "for indexstop, row in enumerate(corpus):\n",
        "  tokens = word_tokenize(str(row))\n",
        "  filtered_text = [t for t in tokens if not t.lower() in stopwords.words(\"turkish\")]\n",
        "  corpus[indexstop] = \" \".join(filtered_text)\n",
        "  #corpus.replace(str(row), \" \".join(filtered_text))\n",
        "\n"
      ],
      "metadata": {
        "id": "wtGRPRb7jZht",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35967915-86cb-4ff2-f142-f0cdbc9007ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "possible_labels = data.category.unique()\n",
        "\n",
        "label_dict = {}\n",
        "for index, possible_label in enumerate(possible_labels):\n",
        "    label_dict[possible_label] = index\n",
        "label_dict\n",
        "data['label'] = data.category.replace(label_dict)\n",
        "\n"
      ],
      "metadata": {
        "id": "2m0rKAFPTdvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TFIDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "xBig = vectorizer.fit_transform(corpus)\n",
        "y = data['label'].values\n",
        "\n"
      ],
      "metadata": {
        "id": "qEjq_brDqbTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#selectKbest\n",
        "#Kütüphaneleri yükleme\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "#Ki kare testine göre en iyi sonuç veren 2 özelliği seç\n",
        "features = SelectKBest(chi2, k = 2000)\n",
        "#features = SelectKBest(k = 2000)\n",
        "x = features.fit_transform(xBig, y)\n",
        "#Azaltılmış Özellikler\n",
        "print('Orjinal Özellik Sayısı:', xBig.shape[1])\n",
        "print('Seçilmiş Özellik Sayısı:', x.shape[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSe4qYA1ehmW",
        "outputId": "eed0581f-01df-4b23-cf3b-23758d8584e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Orjinal Özellik Sayısı: 34710\n",
            "Seçilmiş Özellik Sayısı: 2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#################naive bayes#############################\n",
        "# Define the K-fold Cross Validator\n",
        "kfold = KFold(n_splits=10, shuffle=True)\n",
        "\n",
        "# K-fold Cross Validation model evaluation\n",
        "fold_no = 1\n",
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "prec_per_fold = []\n",
        "recall_per_fold = []\n",
        "f1_per_fold = []\n",
        "confmat_per_fold = np.zeros((categoryNum, categoryNum),dtype=int)\n",
        "predictTimeTotal = 0;\n",
        "for train, test in kfold.split(x, y):\n",
        "  #veri seti: 5692 öznitelikten oluşan bir arff dosyası\n",
        "  modelNB = MultinomialNB()\n",
        "\n",
        "  # Generate a print\n",
        "  print(\"--\")\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "  #train the model\n",
        "  history = modelNB.fit(x[train],y[train])\n",
        "\n",
        "  start = time.process_time();\n",
        "  y_pred = modelNB.predict(x[test]);\n",
        "  end = time.process_time();\n",
        "  ac=accuracy_score(y[test],y_pred);\n",
        "  acc_per_fold.append(ac);\n",
        "\n",
        "  cm = confusion_matrix(y[test], y_pred);\n",
        "\n",
        "  \n",
        "  # Print f1, precision, and recall scores\n",
        "  precision_score_ = precision_score(y[test], y_pred , average=\"macro\")\n",
        "  recall_score_ = recall_score(y[test], y_pred , average=\"macro\")\n",
        "  f1_score_ = f1_score(y[test], y_pred , average=\"macro\")\n",
        "  confmat_ = confusion_matrix(y[test],y_pred, labels=[0, 1, 2, 3, 4, 5, 6])\n",
        "  print(precision_score_)\n",
        "  print(recall_score_)\n",
        "  print(f1_score_)\n",
        "  print(confmat_)\n",
        "  prec_per_fold.append(precision_score_)\n",
        "  recall_per_fold.append(recall_score_)\n",
        "  f1_per_fold.append(f1_score_)\n",
        "  confmat_per_fold = np.add(confmat_per_fold, confmat_) \n",
        "  predictTimeTotal += end - start;\n",
        " \n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1\n",
        "\n",
        "print(\"acc: \", np.mean(acc_per_fold))\n",
        "print(\"prec: \", np.mean(prec_per_fold))\n",
        "print(\"recall: \", np.mean(recall_per_fold))\n",
        "print(\"f1: \", np.mean(f1_per_fold))\n",
        "print(\"confusion matrix:\")\n",
        "print(confmat_per_fold)\n",
        "print(\"predictTimeTotal: \", predictTimeTotal)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HA7yvI78hPt4",
        "outputId": "124d183e-d13e-4301-c530-b26279a70149"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--\n",
            "Training for fold 1 ...\n",
            "0.9000441374161089\n",
            "0.8996436686519108\n",
            "0.8990925514958412\n",
            "[[65  3  0  1  2  0  1]\n",
            " [ 7 48  1  2  0  2  1]\n",
            " [ 3  2 66  0  2  1  2]\n",
            " [ 0  2  2 61  2  0  0]\n",
            " [ 0  0  1  0 69  1  0]\n",
            " [ 0  0  0  0  0 73  0]\n",
            " [ 0  4  1  4  1  0 60]]\n",
            "--\n",
            "Training for fold 2 ...\n",
            "0.9199091219157867\n",
            "0.9190238066815752\n",
            "0.9180952306038334\n",
            "[[62  2  3  0  0  0  1]\n",
            " [ 5 51  3  3  0  0  2]\n",
            " [ 1  0 63  0  0  1  2]\n",
            " [ 1  0  0 61  1  0  1]\n",
            " [ 1  0  0  0 81  0  0]\n",
            " [ 2  1  1  1  0 83  1]\n",
            " [ 0  0  2  0  3  0 51]]\n",
            "--\n",
            "Training for fold 3 ...\n",
            "0.8971511124152503\n",
            "0.8921809776784476\n",
            "0.8928710838465239\n",
            "[[77  3  2  0  0  0  0]\n",
            " [ 6 52  6  2  1  0  2]\n",
            " [ 1  1 68  2  0  2  1]\n",
            " [ 6  0  1 52  2  0  1]\n",
            " [ 0  0  1  0 60  0  0]\n",
            " [ 0  1  1  0  1 72  0]\n",
            " [ 1  2  2  2  2  0 57]]\n",
            "--\n",
            "Training for fold 4 ...\n",
            "0.9005852753035899\n",
            "0.9048735259676352\n",
            "0.9010884285363744\n",
            "[[58  3  1  0  1  0  0]\n",
            " [ 8 65  5  0  0  0  2]\n",
            " [ 4  1 45  0  3  0  1]\n",
            " [ 2  0  0 76  0  0  1]\n",
            " [ 0  1  3  0 55  0  0]\n",
            " [ 0  0  0  0  0 76  0]\n",
            " [ 1  1  4  0  4  0 69]]\n",
            "--\n",
            "Training for fold 5 ...\n",
            "0.8835182126200399\n",
            "0.8791937745024974\n",
            "0.879825266843893\n",
            "[[59  1  6  1  1  0  0]\n",
            " [ 2 58  4  3  1  0  5]\n",
            " [ 2  1 60  2  2  2  3]\n",
            " [ 0  1  2 69  0  0  2]\n",
            " [ 1  0  0  1 70  0  1]\n",
            " [ 2  0  2  0  0 62  0]\n",
            " [ 0  0  7  1  2  1 53]]\n",
            "--\n",
            "Training for fold 6 ...\n",
            "0.8975265874832721\n",
            "0.8957561175391667\n",
            "0.896386996883315\n",
            "[[56  8  0  1  2  0  2]\n",
            " [ 6 61  4  0  1  0  1]\n",
            " [ 4  2 53  0  1  0  2]\n",
            " [ 2  1  1 78  0  0  0]\n",
            " [ 0  1  2  0 75  0  0]\n",
            " [ 1  1  0  0  1 62  0]\n",
            " [ 0  0  4  0  2  0 55]]\n",
            "--\n",
            "Training for fold 7 ...\n",
            "0.9205211087608577\n",
            "0.9215587688878873\n",
            "0.919991120777049\n",
            "[[66  3  1  0  0  0  0]\n",
            " [ 7 55  4  0  1  0  1]\n",
            " [ 2  3 63  0  2  0  1]\n",
            " [ 1  0  0 64  0  0  0]\n",
            " [ 0  0  0  0 62  0  0]\n",
            " [ 2  0  1  2  0 80  1]\n",
            " [ 0  1  3  1  1  1 61]]\n",
            "--\n",
            "Training for fold 8 ...\n",
            "0.9149943810117194\n",
            "0.9128662657044267\n",
            "0.9119805431852618\n",
            "[[67  3  0  0  0  0  1]\n",
            " [ 6 61  5  1  1  1  0]\n",
            " [ 1  1 69  0  0  0  1]\n",
            " [ 0  0  0 71  2  0  1]\n",
            " [ 0  0  1  0 64  0  0]\n",
            " [ 1  0  2  2  0 48  0]\n",
            " [ 1  4  5  2  2  0 66]]\n",
            "--\n",
            "Training for fold 9 ...\n",
            "0.9154266451181382\n",
            "0.9099344022229638\n",
            "0.9107489018668347\n",
            "[[61  2  0  0  0  0  1]\n",
            " [ 5 48  3  1  0  0  2]\n",
            " [ 5  0 64  0  0  1  3]\n",
            " [ 4  0  0 65  0  0  0]\n",
            " [ 0  0  2  0 78  0  0]\n",
            " [ 2  1  2  0  0 64  0]\n",
            " [ 0  0  4  2  3  0 67]]\n",
            "--\n",
            "Training for fold 10 ...\n",
            "0.8883620484557538\n",
            "0.8873361506718416\n",
            "0.8855506034622109\n",
            "[[69  1  0  2  0  1  0]\n",
            " [ 9 60  3  3  1  0  2]\n",
            " [ 6  3 64  1  1  0  3]\n",
            " [ 3  1  1 59  0  0  0]\n",
            " [ 1  0  2  1 65  0  0]\n",
            " [ 0  1  1  1  0 45  0]\n",
            " [ 0  1  2  3  3  1 70]]\n",
            "acc:  0.9026530612244897\n",
            "prec:  0.9038038630500518\n",
            "recall:  0.9022367458508352\n",
            "f1:  0.9015630727501136\n",
            "confusion matrix:\n",
            "[[640  29  13   5   6   1   6]\n",
            " [ 61 559  38  15   6   3  18]\n",
            " [ 29  14 615   5  11   7  19]\n",
            " [ 19   5   7 656   7   0   6]\n",
            " [  3   2  12   2 679   1   1]\n",
            " [ 10   5  10   6   2 665   2]\n",
            " [  3  13  34  15  23   3 609]]\n",
            "predictTimeTotal:  0.0066664980001860386\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJsDYgQqXGCZ",
        "outputId": "2c3786e3-8485-4873-d062-175a9df8f30d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--\n",
            "Training for fold 1 ...\n",
            "0.8706370774142945\n",
            "0.8720029284030996\n",
            "0.8698461320612629\n",
            "[[56  6  0  2  3  0  0]\n",
            " [ 2 56  2  1  1  0  2]\n",
            " [ 4  3 65  4  3  1  5]\n",
            " [ 2  0  0 66  1  0  2]\n",
            " [ 1  1  0  1 72  0  0]\n",
            " [ 0  2  1  1  0 65  1]\n",
            " [ 1  2  5  3  0  0 47]]\n",
            "--\n",
            "Training for fold 2 ...\n",
            "0.8964593105864986\n",
            "0.8964288503569667\n",
            "0.8962147963395326\n",
            "[[50  4  2  1  0  1  1]\n",
            " [ 4 59  5  0  0  0  0]\n",
            " [ 1  5 52  1  2  1  3]\n",
            " [ 0  0  1 66  0  0  2]\n",
            " [ 0  1  1  0 74  0  3]\n",
            " [ 0  0  0  0  0 75  0]\n",
            " [ 2  0  2  5  1  0 65]]\n",
            "--\n",
            "Training for fold 3 ...\n",
            "0.8970743607926069\n",
            "0.8974132297992401\n",
            "0.8969808073074892\n",
            "[[53  3  0  0  0  1  1]\n",
            " [ 3 61  1  4  0  0  1]\n",
            " [ 0  5 54  0  1  0  7]\n",
            " [ 1  2  1 67  0  1  1]\n",
            " [ 0  0  3  0 68  0  1]\n",
            " [ 1  0  0  0  0 66  0]\n",
            " [ 0  3  4  1  5  0 70]]\n",
            "--\n",
            "Training for fold 4 ...\n",
            "0.8741523001422836\n",
            "0.8713388539281396\n",
            "0.8716350726330993\n",
            "[[78  5  3  1  2  0  1]\n",
            " [ 6 52  2  1  2  0  3]\n",
            " [ 4  1 52  0  4  0  2]\n",
            " [ 0  1  1 59  1  1  1]\n",
            " [ 0  2  0  1 71  0  0]\n",
            " [ 1  0  0  1  1 60  0]\n",
            " [ 1  4  4  2  4  0 55]]\n",
            "--\n",
            "Training for fold 5 ...\n",
            "0.8774886737207618\n",
            "0.8778353269834421\n",
            "0.8770429619080247\n",
            "[[56  2  2  1  1  1  0]\n",
            " [ 4 73  5  2  0  0  3]\n",
            " [ 3  2 53  1  2  1  5]\n",
            " [ 2  0  1 73  0  1  2]\n",
            " [ 0  1  2  2 52  1  2]\n",
            " [ 0  2  2  0  0 64  0]\n",
            " [ 0  0  2  3  1  1 59]]\n",
            "--\n",
            "Training for fold 6 ...\n",
            "0.8864481102058742\n",
            "0.885693958818959\n",
            "0.8856381890762196\n",
            "[[65  5  0  0  2  0  3]\n",
            " [ 5 45  4  2  0  0  4]\n",
            " [ 4  1 56  1  2  0  2]\n",
            " [ 1  1  1 72  0  0  0]\n",
            " [ 0  1  0  0 61  0  2]\n",
            " [ 0  0  2  0  0 76  0]\n",
            " [ 0  1  6  2  1  1 61]]\n",
            "--\n",
            "Training for fold 7 ...\n",
            "0.8685044901117394\n",
            "0.8700495633959431\n",
            "0.8687761741850616\n",
            "[[68  3  2  2  0  0  3]\n",
            " [ 5 60  3  2  2  0  3]\n",
            " [ 5  2 58  2  0  3  3]\n",
            " [ 0  3  0 61  0  0  1]\n",
            " [ 0  0  4  2 64  0  0]\n",
            " [ 2  0  0  0  0 61  0]\n",
            " [ 0  1  6  1  4  1 53]]\n",
            "--\n",
            "Training for fold 8 ...\n",
            "0.8725778356616021\n",
            "0.8745286390510143\n",
            "0.8728029530716366\n",
            "[[60 10  0  2  2  0  0]\n",
            " [ 3 48  1  3  0  1  7]\n",
            " [ 1  1 57  2  1  1  3]\n",
            " [ 1  1  2 66  0  0  0]\n",
            " [ 0  0  0  0 69  1  0]\n",
            " [ 1  1  0  1  0 60  1]\n",
            " [ 2  1  5  2  4  1 68]]\n",
            "--\n",
            "Training for fold 9 ...\n",
            "0.8830711275999146\n",
            "0.8830561756678527\n",
            "0.8827258929493612\n",
            "[[62  4  2  0  2  0  1]\n",
            " [ 1 59  3  1  0  1  4]\n",
            " [ 3  1 50  4  1  1  3]\n",
            " [ 0  1  1 53  1  0  2]\n",
            " [ 1  1  2  0 74  0  1]\n",
            " [ 0  1  1  0  0 75  3]\n",
            " [ 0  2  4  2  1  0 61]]\n",
            "--\n",
            "Training for fold 10 ...\n",
            "0.8589964712740554\n",
            "0.866852651991971\n",
            "0.8611111715546682\n",
            "[[55  2  4  1  2  0  1]\n",
            " [ 8 58  4  2  4  0  2]\n",
            " [ 3  3 66  2  2  3  6]\n",
            " [ 0  0  1 73  0  0  2]\n",
            " [ 1  0  1  0 55  0  0]\n",
            " [ 1  3  1  0  1 66  0]\n",
            " [ 0  1  2  0  3  2 49]]\n",
            "acc:  0.8793877551020408\n",
            "prec:  0.8785409757509631\n",
            "recall:  0.8795200178396627\n",
            "f1:  0.8782774151086356\n",
            "confusion matrix:\n",
            "[[603  44  15  10  14   3  11]\n",
            " [ 41 571  30  18   9   2  29]\n",
            " [ 28  24 563  17  18  11  39]\n",
            " [  7   9   9 656   3   3  13]\n",
            " [  3   7  13   6 660   2   9]\n",
            " [  6   9   7   3   2 668   5]\n",
            " [  6  15  40  21  24   6 588]]\n",
            "predictTimeTotal:  0.3848534790000713\n"
          ]
        }
      ],
      "source": [
        "#################random forest#############################\n",
        "\n",
        "# Define the K-fold Cross Validator\n",
        "kfold = KFold(n_splits=10, shuffle=True)\n",
        "\n",
        "# K-fold Cross Validation model evaluation\n",
        "fold_no = 1\n",
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "prec_per_fold = []\n",
        "recall_per_fold = []\n",
        "f1_per_fold = []\n",
        "confmat_per_fold = np.zeros((categoryNum, categoryNum),dtype=int)\n",
        "predictTimeTotal = 0;\n",
        "for train, test in kfold.split(x, y):\n",
        "  #veri seti: 5692 öznitelikten oluşan bir arff dosyası\n",
        "  modelRF = RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "  # Generate a print\n",
        "  print(\"--\")\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "  #train the model\n",
        "  history = modelRF.fit(x[train],y[train])\n",
        "\n",
        "  start = time.process_time();\n",
        "  y_pred = modelRF.predict(x[test]);\n",
        "  end = time.process_time();\n",
        "  ac=accuracy_score(y[test],y_pred);\n",
        "  acc_per_fold.append(ac);\n",
        "\n",
        "  cm = confusion_matrix(y[test], y_pred);\n",
        "\n",
        "  \n",
        "  # Print f1, precision, and recall scores\n",
        "  precision_score_ = precision_score(y[test], y_pred , average=\"macro\")\n",
        "  recall_score_ = recall_score(y[test], y_pred , average=\"macro\")\n",
        "  f1_score_ = f1_score(y[test], y_pred , average=\"macro\")\n",
        "  confmat_ = confusion_matrix(y[test],y_pred, labels=[0, 1, 2, 3, 4, 5, 6])\n",
        "  print(precision_score_)\n",
        "  print(recall_score_)\n",
        "  print(f1_score_)\n",
        "  print(confmat_)\n",
        "  prec_per_fold.append(precision_score_)\n",
        "  recall_per_fold.append(recall_score_)\n",
        "  f1_per_fold.append(f1_score_)\n",
        "  confmat_per_fold = np.add(confmat_per_fold, confmat_) \n",
        "  predictTimeTotal += end - start;\n",
        " \n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1\n",
        "\n",
        "print(\"acc: \", np.mean(acc_per_fold))\n",
        "print(\"prec: \", np.mean(prec_per_fold))\n",
        "print(\"recall: \", np.mean(recall_per_fold))\n",
        "print(\"f1: \", np.mean(f1_per_fold))\n",
        "print(\"confusion matrix:\")\n",
        "print(confmat_per_fold)\n",
        "print(\"predictTimeTotal: \", predictTimeTotal)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYMvWOFv0H8w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db10a784-21a7-470f-9deb-eef7b57cd345"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--\n",
            "Training for fold 1 ...\n",
            "0.9016405774005591\n",
            "0.9020264786149648\n",
            "0.9013317748171643\n",
            "[[58  2  4  1  0  1  1]\n",
            " [ 1 54  3  1  0  0  4]\n",
            " [ 2  1 64  2  1  1  6]\n",
            " [ 1  1  0 51  1  0  0]\n",
            " [ 1  1  2  1 71  0  1]\n",
            " [ 1  0  0  0  0 76  0]\n",
            " [ 0  1  3  2  1  0 68]]\n",
            "--\n",
            "Training for fold 2 ...\n",
            "0.9091689150326172\n",
            "0.909401847399135\n",
            "0.9087313117082214\n",
            "[[71  2  2  1  0  0  3]\n",
            " [ 5 54  3  2  0  1  0]\n",
            " [ 3  4 56  0  0  0  1]\n",
            " [ 2  0  0 58  0  0  0]\n",
            " [ 0  0  2  0 67  0  1]\n",
            " [ 0  0  1  2  0 77  0]\n",
            " [ 0  1  3  2  1  2 63]]\n",
            "--\n",
            "Training for fold 3 ...\n",
            "0.9159249021000173\n",
            "0.9137595065163107\n",
            "0.9140402299757059\n",
            "[[56  5  2  1  3  0  0]\n",
            " [ 3 65  5  2  0  0  0]\n",
            " [ 2  1 60  0  1  0  2]\n",
            " [ 1  2  1 70  0  0  1]\n",
            " [ 0  0  0  0 72  0  0]\n",
            " [ 0  1  0  1  1 65  0]\n",
            " [ 0  0  4  3  0  0 60]]\n",
            "--\n",
            "Training for fold 4 ...\n",
            "0.9056908866461837\n",
            "0.9063444446041489\n",
            "0.9054320049332366\n",
            "[[64  5  4  2  2  0  0]\n",
            " [ 3 81  4  1  2  0  1]\n",
            " [ 2  4 49  1  0  0  2]\n",
            " [ 0  0  0 64  0  0  1]\n",
            " [ 1  0  1  1 62  0  1]\n",
            " [ 2  0  0  1  0 60  1]\n",
            " [ 0  2  2  1  0  0 63]]\n",
            "--\n",
            "Training for fold 5 ...\n",
            "0.9178175419495795\n",
            "0.9169329246435539\n",
            "0.9169663082710835\n",
            "[[67  4  2  2  0  1  0]\n",
            " [ 5 57  2  0  0  0  1]\n",
            " [ 2  3 71  1  0  1  2]\n",
            " [ 0  2  0 70  0  0  1]\n",
            " [ 1  1  1  0 67  0  0]\n",
            " [ 0  0  1  0  0 53  0]\n",
            " [ 0  2  6  1  0  0 63]]\n",
            "--\n",
            "Training for fold 6 ...\n",
            "0.9161347712305145\n",
            "0.9139402527656821\n",
            "0.9136548173677204\n",
            "[[55  8  1  2  1  0  1]\n",
            " [ 1 55  0  2  2  0  3]\n",
            " [ 2  4 57  1  0  0  1]\n",
            " [ 1  1  0 69  0  0  0]\n",
            " [ 0  0  0  2 71  0  2]\n",
            " [ 1  0  2  1  1 71  0]\n",
            " [ 0  0  1  0  0  0 71]]\n",
            "--\n",
            "Training for fold 7 ...\n",
            "0.919141102967768\n",
            "0.9182735740771454\n",
            "0.9184291456213037\n",
            "[[59  2  2  0  0  0  1]\n",
            " [ 0 57  2  1  1  1  1]\n",
            " [ 1  4 55  2  2  1  0]\n",
            " [ 0  0  0 79  1  0  0]\n",
            " [ 1  0  2  1 61  0  1]\n",
            " [ 2  0  1  0  0 70  1]\n",
            " [ 0  0  5  2  1  0 70]]\n",
            "--\n",
            "Training for fold 8 ...\n",
            "0.9401514655391324\n",
            "0.9409772402804204\n",
            "0.9402110073123193\n",
            "[[70  3  2  1  0  0  2]\n",
            " [ 1 62  0  1  1  1  1]\n",
            " [ 2  0 66  0  0  0  1]\n",
            " [ 0  2  1 71  0  0  1]\n",
            " [ 0  0  1  0 66  0  1]\n",
            " [ 0  2  0  0  0 70  0]\n",
            " [ 0  1  3  0  1  0 56]]\n",
            "--\n",
            "Training for fold 9 ...\n",
            "0.913311582907011\n",
            "0.9109864543306979\n",
            "0.911817109643194\n",
            "[[57  6  0  0  0  0  1]\n",
            " [ 2 72  0  1  1  0  3]\n",
            " [ 1  1 66  1  0  1  4]\n",
            " [ 0  3  1 62  0  0  2]\n",
            " [ 0  0  2  0 63  0  0]\n",
            " [ 0  1  1  0  0 67  0]\n",
            " [ 0  1  5  3  3  0 59]]\n",
            "--\n",
            "Training for fold 10 ...\n",
            "0.8886346320048506\n",
            "0.8855035974242585\n",
            "0.8863154118749472\n",
            "[[54  2  2  2  0  0  0]\n",
            " [ 1 55  7  1  0  0  4]\n",
            " [ 2  2 69  1  2  2  4]\n",
            " [ 1  1  1 76  0  0  0]\n",
            " [ 2  2  5  0 62  0  0]\n",
            " [ 0  0  0  0  1 65  0]\n",
            " [ 4  1  5  0  1  0 53]]\n",
            "acc:  0.9118367346938776\n",
            "prec:  0.9127616377778234\n",
            "recall:  0.9118146320656318\n",
            "f1:  0.9116929121524894\n",
            "confusion matrix:\n",
            "[[611  39  21  12   6   2   9]\n",
            " [ 22 612  26  12   7   3  18]\n",
            " [ 19  24 613   9   6   6  23]\n",
            " [  6  12   4 670   2   0   6]\n",
            " [  6   4  16   5 662   0   7]\n",
            " [  6   4   6   5   3 674   2]\n",
            " [  4   9  37  14   8   2 626]]\n",
            "predictTimeTotal:  8.39268655900014\n"
          ]
        }
      ],
      "source": [
        "#################  DVM  #############################\n",
        "\n",
        "# Define the K-fold Cross Validator\n",
        "kfold = KFold(n_splits=10, shuffle=True)\n",
        "\n",
        "# K-fold Cross Validation model evaluation\n",
        "fold_no = 1\n",
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "prec_per_fold = []\n",
        "recall_per_fold = []\n",
        "f1_per_fold = []\n",
        "confmat_per_fold = np.zeros((categoryNum, categoryNum),dtype=int)\n",
        "predictTimeTotal = 0;\n",
        "for train, test in kfold.split(x, y):\n",
        "  #veri seti: 5692 öznitelikten oluşan bir arff dosyası\n",
        "  model = svm.SVC(kernel='linear') # Linear Kernel\n",
        "\n",
        "  # Generate a print\n",
        "  print(\"--\")\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "  #train the model\n",
        "  history = model.fit(x[train],y[train])\n",
        "\n",
        "  start = time.process_time();\n",
        "  y_pred = model.predict(x[test]);\n",
        "  end = time.process_time();\n",
        "  ac=accuracy_score(y[test],y_pred);\n",
        "  acc_per_fold.append(ac);\n",
        "\n",
        "  cm = confusion_matrix(y[test], y_pred);\n",
        "\n",
        "  \n",
        "  # Print f1, precision, and recall scores\n",
        "  precision_score_ = precision_score(y[test], y_pred , average=\"macro\")\n",
        "  recall_score_ = recall_score(y[test], y_pred , average=\"macro\")\n",
        "  f1_score_ = f1_score(y[test], y_pred , average=\"macro\")\n",
        "  confmat_ = confusion_matrix(y[test],y_pred, labels=[0, 1, 2, 3, 4, 5, 6])\n",
        "  print(precision_score_)\n",
        "  print(recall_score_)\n",
        "  print(f1_score_)\n",
        "  print(confmat_)\n",
        "  prec_per_fold.append(precision_score_)\n",
        "  recall_per_fold.append(recall_score_)\n",
        "  f1_per_fold.append(f1_score_)\n",
        "  confmat_per_fold = np.add(confmat_per_fold, confmat_) \n",
        "  predictTimeTotal += end - start;\n",
        " \n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1\n",
        "\n",
        "print(\"acc: \", np.mean(acc_per_fold))\n",
        "print(\"prec: \", np.mean(prec_per_fold))\n",
        "print(\"recall: \", np.mean(recall_per_fold))\n",
        "print(\"f1: \", np.mean(f1_per_fold))\n",
        "print(\"confusion matrix:\")\n",
        "print(confmat_per_fold)\n",
        "print(\"predictTimeTotal: \", predictTimeTotal)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CnWVO0w1YMK",
        "outputId": "a8a47196-b567-4fea-ea4e-f24c2ade3f96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--\n",
            "Training for fold 1 ...\n",
            "0.7493905206958376\n",
            "0.6784460442313066\n",
            "0.679866858283036\n",
            "[[39 16 14 14  0  0  2]\n",
            " [ 3 43 14  7  2  1  1]\n",
            " [ 0  1 49  8  0  0  2]\n",
            " [ 0  1  5 59  1  2  1]\n",
            " [ 0  0  9 10 48  0  0]\n",
            " [ 1  0 16  6  0 52  0]\n",
            " [ 0  1 13  9  2  0 38]]\n",
            "--\n",
            "Training for fold 2 ...\n",
            "0.7822744081459454\n",
            "0.6759076170064259\n",
            "0.6854837065590118\n",
            "[[31  6 15 14  1  0  1]\n",
            " [ 1 41 14  9  1  0  0]\n",
            " [ 0  4 58  5  0  0  3]\n",
            " [ 1  0  5 59  0  1  0]\n",
            " [ 0  0 13 18 40  0  2]\n",
            " [ 0  1 18  7  0 45  0]\n",
            " [ 0  0 16  2  1  0 57]]\n",
            "--\n",
            "Training for fold 3 ...\n",
            "0.796556276257273\n",
            "0.6867925402094471\n",
            "0.6983564843481292\n",
            "[[23  5  6 22  1  0  1]\n",
            " [ 2 52  6 21  1  0  3]\n",
            " [ 0  1 45 10  1  0  2]\n",
            " [ 0  0  1 74  0  0  0]\n",
            " [ 0  1  2 12 49  0  0]\n",
            " [ 0  1  5 15  0 45  0]\n",
            " [ 0  3 10 18  2  0 50]]\n",
            "--\n",
            "Training for fold 4 ...\n",
            "0.7601038407311504\n",
            "0.6869342185275195\n",
            "0.6968872850184519\n",
            "[[30 10 11 20  0  0  0]\n",
            " [ 1 44 14  3  2  0  3]\n",
            " [ 0  2 64 10  1  4  6]\n",
            " [ 0  1  8 61  0  0  0]\n",
            " [ 0  1  8  8 53  2  2]\n",
            " [ 0  1  7  5  1 46  0]\n",
            " [ 1  0 14  7  0  0 39]]\n",
            "--\n",
            "Training for fold 5 ...\n",
            "0.7741438344754277\n",
            "0.6959415209537373\n",
            "0.7058720019758795\n",
            "[[33 10 14 10  1  0  2]\n",
            " [ 2 47 21  6  0  0  0]\n",
            " [ 2  2 52  4  0  1  2]\n",
            " [ 1  0 10 56  0  0  2]\n",
            " [ 0  1 11  7 52  0  2]\n",
            " [ 0  0 10  3  1 58  0]\n",
            " [ 0  1 21  2  0  1 42]]\n",
            "--\n",
            "Training for fold 6 ...\n",
            "0.7958018934866226\n",
            "0.7022497339866449\n",
            "0.7200666070312399\n",
            "[[32  9  9 10  0  0  0]\n",
            " [ 3 43 16  7  1  0  1]\n",
            " [ 1  1 59  9  0  0  0]\n",
            " [ 0  1  7 74  0  1  0]\n",
            " [ 0  0  8 13 37  0  0]\n",
            " [ 0  1  9  9  1 49  2]\n",
            " [ 1  1 12  8  0  0 55]]\n",
            "--\n",
            "Training for fold 7 ...\n",
            "0.7775548050982612\n",
            "0.7531219008204085\n",
            "0.7487050365346511\n",
            "[[41 11  4 14  0  0  3]\n",
            " [ 1 39  3  8  0  0  2]\n",
            " [ 0  4 76  8  2  0  4]\n",
            " [ 0  1  3 57  0  1  2]\n",
            " [ 3  3  4  8 56  1  2]\n",
            " [ 1  4  3  8  0 57  4]\n",
            " [ 1  1  3  4  1  0 42]]\n",
            "--\n",
            "Training for fold 8 ...\n",
            "0.7721702295152431\n",
            "0.6810677245737387\n",
            "0.686906003745292\n",
            "[[32  8 13 20  0  0  1]\n",
            " [ 2 40 14 10  1  0  0]\n",
            " [ 0  3 64  2  0  1  2]\n",
            " [ 0  1  7 55  0  1  0]\n",
            " [ 1  0  8 10 42  0  1]\n",
            " [ 0  0 14  5  0 46  0]\n",
            " [ 2  1 15 15  1  0 52]]\n",
            "--\n",
            "Training for fold 9 ...\n",
            "0.7686442429720712\n",
            "0.7003879008603355\n",
            "0.7069516262588981\n",
            "[[31 11 10 12  1  0  1]\n",
            " [ 4 44 25  6  2  0  1]\n",
            " [ 2  5 58  2  0  0  1]\n",
            " [ 0  0  8 68  0  0  0]\n",
            " [ 0  0 12  8 50  0  6]\n",
            " [ 0  0  8  4  0 48  2]\n",
            " [ 0  1  9  7  0  0 43]]\n",
            "--\n",
            "Training for fold 10 ...\n",
            "0.7809108192323743\n",
            "0.7191198875324512\n",
            "0.7177149434776705\n",
            "[[42  4  9 18  1  1  0]\n",
            " [ 1 44 10  6  0  0  1]\n",
            " [ 2  0 50  2  0  0  3]\n",
            " [ 0  1  5 56  0  1  1]\n",
            " [ 1  0 12 12 50  0  1]\n",
            " [ 0  2 12  6  1 60  0]\n",
            " [ 1  3 20  4  1  0 46]]\n",
            "acc:  0.6963265306122449\n",
            "prec:  0.7757550870610206\n",
            "recall:  0.6979969088702015\n",
            "f1:  0.704681055323226\n",
            "confusion matrix:\n",
            "[[334  90 105 154   5   1  11]\n",
            " [ 20 437 137  83  10   1  12]\n",
            " [  7  23 575  60   4   6  25]\n",
            " [  2   6  59 619   1   7   6]\n",
            " [  5   6  87 106 477   3  16]\n",
            " [  2  10 102  68   4 506   8]\n",
            " [  6  12 133  76   8   1 464]]\n",
            "predictTimeTotal:  1.4869536639998842\n"
          ]
        }
      ],
      "source": [
        "#################  knn  #############################\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Define the K-fold Cross Validator\n",
        "kfold = KFold(n_splits=10, shuffle=True)\n",
        "\n",
        "# K-fold Cross Validation model evaluation\n",
        "fold_no = 1\n",
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "prec_per_fold = []\n",
        "recall_per_fold = []\n",
        "f1_per_fold = []\n",
        "confmat_per_fold = np.zeros((categoryNum, categoryNum),dtype=int)\n",
        "predictTimeTotal = 0;\n",
        "for train, test in kfold.split(x, y):\n",
        "  #veri seti: 5692 öznitelikten oluşan bir arff dosyası\n",
        "  modelKN = KNeighborsClassifier(n_neighbors = 5) # Linear Kernel\n",
        "\n",
        "  # Generate a print\n",
        "  print(\"--\")\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "  #train the model\n",
        "  history = modelKN.fit(x[train],y[train])\n",
        "\n",
        "  start = time.process_time();\n",
        "  y_pred = modelKN.predict(x[test]);\n",
        "  end = time.process_time();\n",
        "  ac=accuracy_score(y[test],y_pred);\n",
        "  acc_per_fold.append(ac);\n",
        "\n",
        "  cm = confusion_matrix(y[test], y_pred);\n",
        "\n",
        "  \n",
        "  # Print f1, precision, and recall scores\n",
        "  precision_score_ = precision_score(y[test], y_pred , average=\"macro\")\n",
        "  recall_score_ = recall_score(y[test], y_pred , average=\"macro\")\n",
        "  f1_score_ = f1_score(y[test], y_pred , average=\"macro\")\n",
        "  confmat_ = confusion_matrix(y[test],y_pred, labels=[0, 1, 2, 3, 4, 5, 6])\n",
        "  print(precision_score_)\n",
        "  print(recall_score_)\n",
        "  print(f1_score_)\n",
        "  print(confmat_)\n",
        "  prec_per_fold.append(precision_score_)\n",
        "  recall_per_fold.append(recall_score_)\n",
        "  f1_per_fold.append(f1_score_)\n",
        "  confmat_per_fold = np.add(confmat_per_fold, confmat_) \n",
        "  predictTimeTotal += end - start;\n",
        " \n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1\n",
        "\n",
        "print(\"acc: \", np.mean(acc_per_fold))\n",
        "print(\"prec: \", np.mean(prec_per_fold))\n",
        "print(\"recall: \", np.mean(recall_per_fold))\n",
        "print(\"f1: \", np.mean(f1_per_fold))\n",
        "print(\"confusion matrix:\")\n",
        "print(confmat_per_fold)\n",
        "print(\"predictTimeTotal: \", predictTimeTotal)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x2 = x.toarray()\n",
        "#x2 = x2.reshape(x2.shape[0], x2.shape[1], 1)\n",
        "max_length=x2.shape[1]\n",
        "vocab_size = x2.shape[1]"
      ],
      "metadata": {
        "id": "Ka3_mbEXlLAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "714Nv5qC3-qM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc65b74f-0e98-4593-b150-495336810eef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 5000, 128)         256       \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 640000)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               81920128  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 7)                 903       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 81,921,287\n",
            "Trainable params: 81,921,287\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "--\n",
            "Training for fold 1 ...\n",
            "Epoch 1/10\n",
            "344/344 [==============================] - 17s 28ms/step - loss: 0.2366 - accuracy: 0.9097\n",
            "Epoch 2/10\n",
            "344/344 [==============================] - 10s 28ms/step - loss: 0.0722 - accuracy: 0.9771\n",
            "Epoch 3/10\n",
            "344/344 [==============================] - 10s 28ms/step - loss: 0.0468 - accuracy: 0.9866\n",
            "Epoch 4/10\n",
            "344/344 [==============================] - 10s 28ms/step - loss: 0.0349 - accuracy: 0.9905\n",
            "Epoch 5/10\n",
            "344/344 [==============================] - 10s 28ms/step - loss: 0.0248 - accuracy: 0.9934\n",
            "Epoch 6/10\n",
            "344/344 [==============================] - 10s 28ms/step - loss: 0.0193 - accuracy: 0.9941\n",
            "Epoch 7/10\n",
            "344/344 [==============================] - 10s 28ms/step - loss: 0.0164 - accuracy: 0.9949\n",
            "Epoch 8/10\n",
            "344/344 [==============================] - 10s 28ms/step - loss: 0.0144 - accuracy: 0.9950\n",
            "Epoch 9/10\n",
            "344/344 [==============================] - 10s 28ms/step - loss: 0.0121 - accuracy: 0.9955\n",
            "Epoch 10/10\n",
            "344/344 [==============================] - 10s 28ms/step - loss: 0.0126 - accuracy: 0.9953\n",
            "275/275 - 1s - loss: 0.2023 - accuracy: 0.9498 - 1s/epoch - 5ms/step\n",
            "Score for fold 1: loss of 0.20225994288921356; accuracy of 0.9497816562652588\n",
            "86/86 [==============================] - 1s 6ms/step\n",
            "predictTime:  0.7118574059999787\n",
            "0.9499552822095251\n",
            "0.9498637550217823\n",
            "0.949780701754386\n",
            "[[1311   53]\n",
            " [  85 1299]]\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_1 (Conv1D)           (None, 5000, 128)         256       \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 640000)            0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               81920128  \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 7)                 903       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 81,921,287\n",
            "Trainable params: 81,921,287\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "--\n",
            "Training for fold 2 ...\n",
            "Epoch 1/10\n",
            "344/344 [==============================] - 10s 28ms/step - loss: 0.2288 - accuracy: 0.9098\n",
            "Epoch 2/10\n",
            "344/344 [==============================] - 10s 28ms/step - loss: 0.0738 - accuracy: 0.9773\n",
            "Epoch 3/10\n",
            "344/344 [==============================] - 10s 28ms/step - loss: 0.0457 - accuracy: 0.9850\n",
            "Epoch 4/10\n",
            "344/344 [==============================] - 10s 28ms/step - loss: 0.0331 - accuracy: 0.9894\n",
            "Epoch 5/10\n",
            "344/344 [==============================] - 10s 28ms/step - loss: 0.0269 - accuracy: 0.9919\n",
            "Epoch 6/10\n",
            "344/344 [==============================] - 10s 28ms/step - loss: 0.0192 - accuracy: 0.9942\n",
            "Epoch 7/10\n",
            "344/344 [==============================] - 10s 28ms/step - loss: 0.0145 - accuracy: 0.9945\n",
            "Epoch 8/10\n",
            "344/344 [==============================] - 10s 28ms/step - loss: 0.0127 - accuracy: 0.9956\n",
            "Epoch 9/10\n",
            "344/344 [==============================] - 10s 28ms/step - loss: 0.0107 - accuracy: 0.9960\n",
            "Epoch 10/10\n",
            "344/344 [==============================] - 10s 28ms/step - loss: 0.0101 - accuracy: 0.9963\n",
            "275/275 - 1s - loss: 0.1933 - accuracy: 0.9600 - 1s/epoch - 4ms/step\n",
            "Score for fold 2: loss of 0.19327813386917114; accuracy of 0.9599708914756775\n",
            "86/86 [==============================] - 1s 6ms/step\n",
            "predictTime:  0.700794798000004\n",
            "0.9602462220078807\n",
            "0.960018031084021\n",
            "0.959967304247958\n",
            "[[1332   37]\n",
            " [  73 1306]]\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_2 (Conv1D)           (None, 5000, 128)         256       \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 640000)            0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 128)               81920128  \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 7)                 903       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 81,921,287\n",
            "Trainable params: 81,921,287\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "--\n",
            "Training for fold 3 ...\n",
            "Epoch 1/10\n",
            "344/344 [==============================] - 10s 28ms/step - loss: 0.2421 - accuracy: 0.9078\n",
            "Epoch 2/10\n",
            "344/344 [==============================] - 10s 28ms/step - loss: 0.0821 - accuracy: 0.9746\n",
            "Epoch 3/10\n",
            "344/344 [==============================] - 10s 28ms/step - loss: 0.0503 - accuracy: 0.9839\n",
            "Epoch 4/10\n",
            "344/344 [==============================] - 10s 28ms/step - loss: 0.0360 - accuracy: 0.9892\n",
            "Epoch 5/10\n",
            "344/344 [==============================] - 10s 28ms/step - loss: 0.0280 - accuracy: 0.9912\n",
            "Epoch 6/10\n",
            "344/344 [==============================] - 10s 28ms/step - loss: 0.0245 - accuracy: 0.9927\n",
            "Epoch 7/10\n",
            "344/344 [==============================] - 10s 28ms/step - loss: 0.0173 - accuracy: 0.9945\n",
            "Epoch 8/10\n",
            "344/344 [==============================] - 10s 28ms/step - loss: 0.0148 - accuracy: 0.9950\n",
            "Epoch 9/10\n",
            "344/344 [==============================] - 10s 28ms/step - loss: 0.0138 - accuracy: 0.9947\n",
            "Epoch 10/10\n",
            "344/344 [==============================] - 10s 28ms/step - loss: 0.0106 - accuracy: 0.9958\n",
            "275/275 - 1s - loss: 0.1802 - accuracy: 0.9596 - 1s/epoch - 4ms/step\n",
            "Score for fold 3: loss of 0.18018129467964172; accuracy of 0.9596070051193237\n",
            "86/86 [==============================] - 1s 6ms/step\n",
            "predictTime:  0.6886933940000404\n",
            "0.9596243813139874\n",
            "0.959857492255878\n",
            "0.9596024878874876\n",
            "[[1304   39]\n",
            " [  72 1333]]\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_3 (Conv1D)           (None, 5000, 128)         256       \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 640000)            0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               81920128  \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 7)                 903       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 81,921,287\n",
            "Trainable params: 81,921,287\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "--\n",
            "Training for fold 4 ...\n",
            "Epoch 1/10\n",
            "344/344 [==============================] - 10s 28ms/step - loss: 0.2553 - accuracy: 0.9015\n",
            "Epoch 2/10\n",
            "344/344 [==============================] - 10s 28ms/step - loss: 0.0748 - accuracy: 0.9747\n",
            "Epoch 3/10\n",
            "344/344 [==============================] - 10s 28ms/step - loss: 0.0471 - accuracy: 0.9852\n",
            "Epoch 4/10\n",
            "344/344 [==============================] - 10s 28ms/step - loss: 0.0381 - accuracy: 0.9896\n",
            "Epoch 5/10\n",
            "344/344 [==============================] - 10s 28ms/step - loss: 0.0267 - accuracy: 0.9925\n",
            "Epoch 6/10\n",
            "344/344 [==============================] - 10s 28ms/step - loss: 0.0190 - accuracy: 0.9944\n",
            "Epoch 7/10\n",
            "344/344 [==============================] - 10s 28ms/step - loss: 0.0156 - accuracy: 0.9958\n",
            "Epoch 8/10\n",
            "344/344 [==============================] - 10s 28ms/step - loss: 0.0123 - accuracy: 0.9962\n",
            "Epoch 9/10\n",
            "344/344 [==============================] - 10s 28ms/step - loss: 0.0103 - accuracy: 0.9965\n",
            "Epoch 10/10\n",
            "344/344 [==============================] - 10s 28ms/step - loss: 0.0082 - accuracy: 0.9973\n",
            "275/275 - 1s - loss: 0.1885 - accuracy: 0.9582 - 1s/epoch - 4ms/step\n",
            "Score for fold 4: loss of 0.1885460615158081; accuracy of 0.9581514000892639\n",
            "86/86 [==============================] - 1s 6ms/step\n",
            "predictTime:  0.6772851480000099\n",
            "0.958154801411764\n",
            "0.9581497050647502\n",
            "0.9581511112759065\n",
            "[[1320   56]\n",
            " [  59 1313]]\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_4 (Conv1D)           (None, 5000, 128)         256       \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 640000)            0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 128)               81920128  \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 7)                 903       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 81,921,287\n",
            "Trainable params: 81,921,287\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "--\n",
            "Training for fold 5 ...\n",
            "Epoch 1/10\n",
            "344/344 [==============================] - 10s 28ms/step - loss: 0.2279 - accuracy: 0.9091\n",
            "Epoch 2/10\n",
            "344/344 [==============================] - 10s 28ms/step - loss: 0.0719 - accuracy: 0.9770\n",
            "Epoch 3/10\n",
            "344/344 [==============================] - 10s 28ms/step - loss: 0.0454 - accuracy: 0.9861\n",
            "Epoch 4/10\n",
            "344/344 [==============================] - 10s 28ms/step - loss: 0.0309 - accuracy: 0.9905\n",
            "Epoch 5/10\n",
            "344/344 [==============================] - 10s 28ms/step - loss: 0.0243 - accuracy: 0.9924\n",
            "Epoch 6/10\n",
            "344/344 [==============================] - 10s 28ms/step - loss: 0.0205 - accuracy: 0.9924\n",
            "Epoch 7/10\n",
            "344/344 [==============================] - 10s 28ms/step - loss: 0.0160 - accuracy: 0.9945\n",
            "Epoch 8/10\n",
            "344/344 [==============================] - 10s 29ms/step - loss: 0.0154 - accuracy: 0.9955\n",
            "Epoch 9/10\n",
            "344/344 [==============================] - 10s 28ms/step - loss: 0.0117 - accuracy: 0.9965\n",
            "Epoch 10/10\n",
            "344/344 [==============================] - 10s 28ms/step - loss: 0.0121 - accuracy: 0.9961\n",
            "275/275 - 1s - loss: 0.1787 - accuracy: 0.9563 - 1s/epoch - 4ms/step\n",
            "Score for fold 5: loss of 0.17873206734657288; accuracy of 0.9563318490982056\n",
            "86/86 [==============================] - 1s 6ms/step\n",
            "predictTime:  0.6966185489999361\n",
            "0.9562809776830905\n",
            "0.9567222526506779\n",
            "0.9563185503099667\n",
            "[[1290   41]\n",
            " [  79 1338]]\n",
            "acc:  0.9567685604095459\n",
            "prec:  0.9568523329252496\n",
            "recall:  0.956922247215422\n",
            "f1:  0.956764031095141\n",
            "confusion matrix:\n",
            "[[6557  226]\n",
            " [ 368 6589]]\n",
            "predictTimeTotal:  3.475249294999969\n"
          ]
        }
      ],
      "source": [
        "# Define the K-fold Cross Validator\n",
        "kfold = KFold(n_splits=5, shuffle=True)\n",
        "\n",
        "# K-fold Cross Validation model evaluation\n",
        "fold_no = 1\n",
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "prec_per_fold = []\n",
        "recall_per_fold = []\n",
        "f1_per_fold = []\n",
        "confmat_per_fold = np.zeros((categoryNum, categoryNum),dtype=int)\n",
        "predictTimeTotal = 0;\n",
        "for train, test in kfold.split(x2, y):\n",
        "  #veri seti: vocab_size öznitelikten oluşan bir arff dosyası\n",
        "  modelCNN = tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Conv1D(128, 1, activation=\"relu\", input_shape=(vocab_size,1)), #dropout 0.2 91,5 droopout 0.05 88 dropout 0.3 89\n",
        "      tf.keras.layers.Flatten(input_shape=(vocab_size,1)),\n",
        "      tf.keras.layers.Dense(128,activation='relu'),\n",
        "      tf.keras.layers.Dropout(0.3),\n",
        "      tf.keras.layers.Dense(7)\n",
        "      ])\n",
        "  #inputs = Input(shape=(max_length, ))\n",
        "  #embeddings_layer = Embedding(input_dim=vocab_size, output_dim=128,  input_length=max_length)\n",
        "  #conv = Conv1D(32, 7, padding=\"same\") ## Channels last\n",
        "  #dense = Dense(7)\n",
        "  #embedModel = embeddings_layer(inputs)\n",
        "  #embedModel = conv(embedModel)\n",
        "  #embedModel = tf.reduce_max(embedModel, axis=1)\n",
        "  #output = dense(embedModel)\n",
        "  #modelCNN = Model(inputs=inputs, outputs=output)\n",
        "\n",
        "\n",
        "  modelCNN.summary()\n",
        "  #define loss function variable\n",
        "  loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "  \n",
        "  # compile the model\n",
        "  modelCNN.compile(optimizer='adam',\n",
        "             loss=loss_fn,\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "\n",
        "  # Generate a print\n",
        "  print(\"--\")\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "  #train the model\n",
        "  history = modelCNN.fit(x2[train],y[train],epochs=10)\n",
        "  scores = modelCNN.evaluate(x2[test],y[test],verbose=2, batch_size=10)\n",
        "  print(f'Score for fold {fold_no}: {modelCNN.metrics_names[0]} of {scores[0]}; {modelCNN.metrics_names[1]} of {scores[1]}')\n",
        "  acc_per_fold.append(scores[1])\n",
        "  loss_per_fold.append(scores[0])\n",
        "  \n",
        "  start = time.process_time();\n",
        "  y_pred1 = modelCNN.predict(x2[test])\n",
        "  end = time.process_time();\n",
        "  print(\"predictTime: \", end - start)\n",
        "  y_pred = np.argmax(y_pred1, axis=1)\n",
        "  # Print f1, precision, and recall scores\n",
        "  precision_score_ = precision_score(y[test], y_pred , average=\"macro\")\n",
        "  recall_score_ = recall_score(y[test], y_pred , average=\"macro\")\n",
        "  f1_score_ = f1_score(y[test], y_pred , average=\"macro\")\n",
        "  confmat_ = confusion_matrix(y[test],y_pred, labels=[0, 1, 2, 3, 4, 5, 6])\n",
        "  #confusion_matrix(y_true, y_pred)\n",
        "  print(precision_score_)\n",
        "  print(recall_score_)\n",
        "  print(f1_score_)\n",
        "  print(confmat_)\n",
        "  prec_per_fold.append(precision_score_)\n",
        "  recall_per_fold.append(recall_score_)\n",
        "  f1_per_fold.append(f1_score_)\n",
        "  confmat_per_fold = np.add(confmat_per_fold, confmat_) \n",
        "  predictTimeTotal += end - start;\n",
        " \n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1\n",
        "\n",
        "print(\"acc: \", np.mean(acc_per_fold))\n",
        "print(\"prec: \", np.mean(prec_per_fold))\n",
        "print(\"recall: \", np.mean(recall_per_fold))\n",
        "print(\"f1: \", np.mean(f1_per_fold))\n",
        "print(\"confusion matrix:\")\n",
        "print(confmat_per_fold)\n",
        "print(\"predictTimeTotal: \", predictTimeTotal)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check am i running at GPU\n",
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ExG6weZJMob7",
        "outputId": "5f8dd346-5fe4-443e-c946-b6ee7e172315"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    }
  ]
}